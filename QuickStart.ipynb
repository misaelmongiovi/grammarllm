{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cdc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammarllm import generate_grammar_parameters, generate_text, get_parsing_table_and_map_tt, create_prompt, chat_template\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e6855",
   "metadata": {},
   "source": [
    "## *Hierachical Classification Example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Grammar Productions\n",
    "productions = { 'S*': [\"<<positive >> A\", \"<<negative >> B\", \"<<neutral >> C\"],\n",
    "                'A': [\"<<happy>>\", \"<<peaceful>>\", \"<<joyful>>\"],\n",
    "                'B': ['<<sad>>', '<<angry>>', '<<frustrated>>'],\n",
    "                'C': ['<<calm>>', '<<indifferent>>', '<<unemotional>>']\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6855b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt and examples for the classification task\n",
    "system_prompt = \"\"\"You are a hierarchical classification assistant. Your task is to classify the user input \n",
    "                    into one of the following hierarchical categories as shown in the followig examples\\n\\n\"\"\"\n",
    "\n",
    "# Define the examples for the classification task\n",
    "examples = [\n",
    "    {\"role\": \"user\", \"content\": \"I just got a promotion!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"positive joyful\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"Nothing ever goes my way.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"negative frustrated\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"The lake was still and quiet.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"neutral calm\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"I miss my family so much.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"negative sad\"}\n",
    "]\n",
    "\n",
    "prompt=create_prompt(\n",
    "    prompt_input=\"It's raining and I feel a bit down.\",\n",
    "    system_prompt=system_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "\n",
    "# Generate the parsing table and terminal token mapping\n",
    "pars_table, map_terminal_tokens = get_parsing_table_and_map_tt(tokenizer, productions)\n",
    "\n",
    "# Generate the grammar parameters\n",
    "LogitProcessor, Streamer = generate_grammar_parameters(\n",
    "    tokenizer, pars_table, map_terminal_tokens\n",
    ")\n",
    "\n",
    "# Generate the output constrained themodel via GrammarLLM \n",
    "output = generate_text(model, tokenizer, prompt, LogitProcessor, Streamer, chat_template)\n",
    "print(output) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b22f6",
   "metadata": {},
   "source": [
    "## *Vocabulary Restriction Example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Grammar Productions\n",
    "productions = {\n",
    "'S*': [\n",
    "    \"<< Yes>> S*\",\n",
    "    \"<< I'm>> S*\",\n",
    "    \"<< very>> S*\",\n",
    "    \"<< happy>> S*\",\n",
    "    \"<< !>> S*\",\n",
    "    \"<< so>> S*\",\n",
    "    \"<< really>> S*\",\n",
    "    \"<< excited>> S*\",\n",
    "    \"<< today>> S*\",\n",
    "    \"<< thanks>> S*\",\n",
    "    \"<< you>> S*\",\n",
    "    \"<< much>> S*\",\n",
    "    \"<< great>> S*\",\n",
    "    \"<< good>> S*\",\n",
    "    \"<< fine>> S*\",\n",
    "    \"<< amazing>> S*\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dab64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the system prompt and examples for the classification task\n",
    "system_prompt = \"\"\"You are a text generation assistant. When generating responses, you must use only the words that\n",
    "                    appear in the provided examples below. You should not introduce any new words outside of those examples.\"\"\"\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\"role\": \"user\", \"content\": \"How are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm very happy\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"Is everything okay?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Yes, I'm so excited!\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"How was your day?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm really happy today!\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"Do you feel good?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Yes, I feel great, thanks!\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"What's up?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm fine, thank you so much!\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"Anything special today?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm very excited and happy today!\"}\n",
    "    ]\n",
    "\n",
    "prompt=create_prompt(\n",
    "    prompt_input=\"Say something of positive:\",\n",
    "    system_prompt=system_prompt,\n",
    "    examples=examples\n",
    "    )\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "\n",
    "# Generate the parsing table and terminal token mapping\n",
    "pars_table, map_terminal_tokens = get_parsing_table_and_map_tt(tokenizer, productions)\n",
    "\n",
    "# Generate the grammar parameters\n",
    "LogitProcessor, Streamer = generate_grammar_parameters(\n",
    "    tokenizer, pars_table, map_terminal_tokens\n",
    ")\n",
    "\n",
    "# Generate the output constrained themodel via GrammarLLM \n",
    "output = generate_text(model, tokenizer, prompt, LogitProcessor, Streamer, chat_template)\n",
    "print(output) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9bf23",
   "metadata": {},
   "source": [
    "## *Structured Generation Example* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Grammar Productions\n",
    "productions = {\n",
    "        'S*': [\"SUBJ PRED OBJ . S*\"],\n",
    "        'SUBJ': [\"IRI\", \"BLANKNODE\"],\n",
    "        'PRED': [\"IRI\"],\n",
    "        'OBJ': [\"IRI\", \"BLANKNODE\", \"LITERAL\"],\n",
    "        'IRI': [\"< URI >\"],\n",
    "        'BLANKNODE': [\"<<_:>> NAME\"],\n",
    "        'LITERAL': [\"\\\" STRING \\\" DESCRIPTION_LANG\"],\n",
    "        'DESCRIPTION_LANG': [\"^^ IRI\", \"@ LANGTAG\", \"ε\"],\n",
    "\n",
    "        'URI': [\n",
    "            # People\n",
    "            \"<<http://example.org/people/MarioRossi>>\",\n",
    "            \"<<http://example.org/people/LuisaVerdi>>\",\n",
    "            \"<<http://example.org/people/GiovanniBianchi>>\",\n",
    "\n",
    "            # Properties\n",
    "            \"<<http://example.org/properties/hasAge>>\",\n",
    "            \"<<http://example.org/properties/hasProfession>>\",\n",
    "            \"<<http://example.org/properties/hasSalary>>\",\n",
    "\n",
    "            # Other types or datatypes\n",
    "            \"<<http://www.w3.org/2001/XMLSchema#decimal>>\",\n",
    "            \"<<http://www.w3.org/2001/XMLSchema#integer>>\",\n",
    "            \"<<http://www.w3.org/2001/XMLSchema#string>>\"\n",
    "        ],\n",
    "\n",
    "        'STRING':[\"alfanum STRING\", \"ε\"],\n",
    "        'NAME': [\"ids NAME_C\"],\n",
    "        'NAME_C': [\"idc NAME_C\", \"ε\"],\n",
    "\n",
    "        'LANGTAG': ['<<it >>', '<<en >>', '<<fr >>', '<<sp >>']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395aedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define regular expressions for terminal tokens\n",
    "regex_alfanum = re.compile(r\"[a-zA-Z0-9]+\")  # es. \"abc123\"\n",
    "regex_right_round_bracket = re.compile(r\"\\)$\")  # match only ')'\n",
    "regex_left_round_bracket = re.compile(r\"\\($\")  # match only '('\n",
    "regex_less_than = re.compile(r\"^<$\") # match only '<'\n",
    "regex_greater_than = re.compile(r\"^>$\") # match only '>'\n",
    "regex_double_quote = re.compile(r'^\\\"$') # match only '\"'\n",
    "regex_datatype = re.compile(r\"^\\^\\^$\")   # match only '^^'\n",
    "regex_langtag = re.compile(r\"^@$\")       # match only '@'\n",
    "regex_dot = re.compile(r\"^\\.$\")  # match only '.'\n",
    "\n",
    "# Starting identifier: must start with a letter or an underscore\n",
    "regex_ids = re.compile(r'[A-Za-z_][A-Za-z0-9_-]*')\n",
    "# Continuation identifier: cannot start with a letter or an underscore\n",
    "regex_idc = re.compile(r'(?![A-Za-z_])[0-9_-][A-Za-z0-9_-]*')\n",
    "\n",
    "\n",
    "regex_dict = {\n",
    "    'regex_alfanum': regex_alfanum,\n",
    "    'regex_)': regex_right_round_bracket,\n",
    "    'regex_(': regex_left_round_bracket,\n",
    "    'regex_<': regex_less_than,\n",
    "    'regex_>': regex_greater_than,\n",
    "    'regex_\"': regex_double_quote,\n",
    "    'regex_^^': regex_datatype,\n",
    "    'regex_@': regex_langtag,\n",
    "    'regex_.': regex_dot,\n",
    "\n",
    "    'regex_ids':regex_ids,\n",
    "    'regex_idc':regex_idc\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd6a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt and examples for the classification task\n",
    "system_prompt = \"\"\"You are an assistant that converts natural language sentences into RDF triples syntax.\n",
    "\n",
    "Follow these rules:\n",
    "\n",
    "1. Use URIs (`<...>`) for:\n",
    "- Identifiable entities such as people, properties, or concepts.\n",
    "- Example:\n",
    "    <http://example.org/people/MarioRossi> <http://example.org/properties/hasFriend> <http://example.org/people/LuisaVerdi> .\n",
    "\n",
    "2. Use literals (`\"...\"`) for:\n",
    "- Plain values such as professions, cities, names, numbers, dates, or booleans.\n",
    "- Add datatypes (`^^<...>`) or language tags (`@lang`) if needed.\n",
    "- Examples:\n",
    "    \"engineer\"@en  \n",
    "    \"40\"^^<http://www.w3.org/2001/XMLSchema#integer>\n",
    "\n",
    "3. Use blank nodes (`_:`) only if:\n",
    "- The object is anonymous and has internal structure (i.e., it has its own properties).\n",
    "- Example:\n",
    "    <http://example.org/people/MarioRossi> <http://example.org/properties/hasAddress> _:b1 .\n",
    "    _:b1 <http://example.org/properties/street> \"Via Roma\" .\n",
    "    _:b1 <http://example.org/properties/city> \"Milano\" .\n",
    "\n",
    "Never use a blank node (`_:`) for simple values like \"engineer\" or \"teacher\". Use a literal (`\"...\"`) instead.\n",
    "\n",
    "Now use the following examples to generate clean and correct RDF triples from user input.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"role\": \"user\", \"content\": \"Mario Rossi is 40 years old.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"<http://example.org/people/MarioRossi> <http://example.org/properties/hasAge> \\\"40\\\" ^^<http://www.w3.org/2001/XMLSchema#integer> .\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"Luisa Verdi is an engineer.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"<http://example.org/people/LuisaVerdi> <http://example.org/properties/hasProfession> \\\"engineer\\\" @en .\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"Giovanni Bianchi earns 55000.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"<http://example.org/people/GiovanniBianchi> <http://example.org/properties/hasSalary> \\\"55000\\\" ^^<http://www.w3.org/2001/XMLSchema#decimal> .\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"Mario Rossi has an anonymous node as a contact.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"<http://example.org/people/MarioRossi> <http://example.org/properties/hasContact> _:ids .\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"Mario Rossi has the profession of teacher.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"<http://example.org/people/MarioRossi> <http://example.org/properties/hasProfession> \\\"teacher\\\" @en .\"}\n",
    "]\n",
    "\n",
    "prompt=create_prompt(\n",
    "    prompt_input=\"Giovanni Bianchi was born 30 years ago.\",\n",
    "    system_prompt=system_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# Initialize tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "\n",
    "# Generate grammar parameters\n",
    "pars_table, map_terminal_tokens = get_parsing_table_and_map_tt(\n",
    "    tokenizer, \n",
    "    productions=productions, \n",
    "    regex_dict=regex_dict,\n",
    ")\n",
    "\n",
    "LogitProcessor, Streamer = generate_grammar_parameters(tokenizer, pars_table, map_terminal_tokens)\n",
    "output = generate_text(model, tokenizer, prompt, LogitProcessor, Streamer, chat_template)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammarllm-env-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
